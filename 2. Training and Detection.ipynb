{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42hJEdo_pfDB"
   },
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbPhYVy_pfDB"
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwhWZMI0pfDC"
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HR-TfDGrpfDC"
   },
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/install/source_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-Cmz2edpfDE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iA1DIq5OpfDE"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJjMHbnDs3Tv"
   },
   "outputs": [],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall protobuf matplotlib -y\n",
    "!pip install protobuf matplotlib==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gin-config==0.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csofht2npfDE",
    "outputId": "ff5471b2-bed2-43f2-959c-327a706527b6"
   },
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "labels = [{'name':'ThumbsUp', 'id':1}, {'name':'ThumbsDown', 'id':2}, {'name':'ThankYou', 'id':3}, {'name':'LiveLong', 'id':4}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C88zyVELpfDC"
   },
   "source": [
    "# 3. Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvf5WccwrFGq",
    "outputId": "49902aeb-0bd7-4298-e1a0-5b4a64eb2064"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWpb_BVUpfDD",
    "outputId": "56ce2a3f-3933-4ee6-8a9d-d5ec65f7d73c"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPFToGZqpfDD",
    "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
   },
   "outputs": [],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4QU7pLpfDE"
   },
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOjuTFbwpfDF"
   },
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8gpNslpfDF"
   },
   "source": [
    "# 5. Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2A0mn4ipfDF"
   },
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQA13-afpfDF",
    "outputId": "907496a4-a39d-4b13-8c2c-e5978ecb1f10"
   },
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vK5lotDpfDF"
   },
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rP43Ph0JpfDG"
   },
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJvfgwWqpfDG"
   },
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMP2XDfQpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3ZsJR-qpfDH",
    "outputId": "cabec5e1-45e6-4f2f-d9cf-297d9c1d0225"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80L7-fdPpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYsgEPx9pfDH",
    "outputId": "8632d48b-91d2-45d9-bcb8-c1b172bf6eed"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqTV2jGBpfDH"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orvRk02UpfDI"
   },
   "source": [
    "# 8. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TYk4_oIpfDI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDnQg-cYpfDI"
   },
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-4')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EmsmbBZpfDI"
   },
   "source": [
    "# 9. Detect from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_MKiuZ4pfDI"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBDbIhNapfDI"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lx3crOhOzITB"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'thumbsup.a037248f-10d6-11ee-b17e-48d890881ebe.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Tpzn1SMry1yK",
    "outputId": "c392a2c5-10fe-4fc4-9998-a1d4c7db2bd3"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsNAaYAo0WVL"
   },
   "source": [
    "# 10. Real Time Detections from your Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall opencv-python-headless -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_grs6OGpfDJ"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzlM4jt0pfDJ"
   },
   "source": [
    "# 10. Freezing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4olHB2npfDJ"
   },
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AjO93QDpfDJ"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6Lsp3tCpfDJ",
    "outputId": "c3828529-bf06-4df5-d7f3-145890ec3edd"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Sw1ULgHpfDJ",
    "outputId": "6fd441e1-9fc9-4889-d072-3395c21e40b6"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTPmdqaXpfDK"
   },
   "source": [
    "# 11. Conversion to TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install numpy cython\n",
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZ6UzY_fpfDK",
    "outputId": "0c84722e-1c2b-4002-d857-80827ade828a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs\n",
      "  Using cached tensorflowjs-4.8.0-py3-none-any.whl (85 kB)\n",
      "Collecting flax<0.6.3,>=0.6.2 (from tensorflowjs)\n",
      "  Using cached flax-0.6.2-py3-none-any.whl (189 kB)\n",
      "Collecting importlib_resources>=5.9.0 (from tensorflowjs)\n",
      "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: jax>=0.3.16 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflowjs) (0.4.12)\n",
      "Requirement already satisfied: tensorflow<3,>=2.12.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflowjs) (2.12.0)\n",
      "INFO: pip is looking at multiple versions of tensorflowjs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflowjs\n",
      "  Using cached tensorflowjs-4.7.0-py3-none-any.whl (85 kB)\n",
      "  Using cached tensorflowjs-4.6.0-py3-none-any.whl (85 kB)\n",
      "  Using cached tensorflowjs-4.5.0-py3-none-any.whl (85 kB)\n",
      "  Using cached tensorflowjs-4.4.0-py3-none-any.whl (85 kB)\n",
      "Collecting flax>=0.6.2 (from tensorflowjs)\n",
      "  Using cached flax-0.6.11-py3-none-any.whl (227 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflowjs)\n",
      "  Using cached protobuf-3.19.6-cp310-cp310-win_amd64.whl (895 kB)\n",
      "Collecting tensorflowjs\n",
      "  Using cached tensorflowjs-4.3.0-py3-none-any.whl (85 kB)\n",
      "  Using cached tensorflowjs-4.2.0-py3-none-any.whl (84 kB)\n",
      "  Using cached tensorflowjs-4.1.0-py3-none-any.whl (84 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflowjs to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tensorflowjs-4.0.0-py3-none-any.whl (83 kB)\n",
      "  Using cached tensorflowjs-3.21.0-py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflowjs) (1.16.0)\n",
      "Collecting tensorflow-hub<0.13,>=0.7.0 (from tensorflowjs)\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Collecting packaging~=20.9 (from tensorflowjs)\n",
      "  Using cached packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: numpy>=1.12 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from flax>=0.6.2->tensorflowjs) (1.23.5)\n",
      "Collecting msgpack (from flax>=0.6.2->tensorflowjs)\n",
      "  Using cached msgpack-1.0.5-cp310-cp310-win_amd64.whl (61 kB)\n",
      "Collecting optax (from flax>=0.6.2->tensorflowjs)\n",
      "  Using cached optax-0.1.5-py3-none-any.whl (164 kB)\n",
      "Collecting orbax-checkpoint (from flax>=0.6.2->tensorflowjs)\n",
      "  Using cached orbax_checkpoint-0.2.6-py3-none-any.whl (84 kB)\n",
      "Collecting tensorstore (from flax>=0.6.2->tensorflowjs)\n",
      "  Downloading tensorstore-0.1.39-cp310-cp310-win_amd64.whl (9.5 MB)\n",
      "                                              0.0/9.5 MB ? eta -:--:--\n",
      "                                              0.0/9.5 MB ? eta -:--:--\n",
      "                                              0.0/9.5 MB ? eta -:--:--\n",
      "                                              0.0/9.5 MB ? eta -:--:--\n",
      "                                              0.0/9.5 MB ? eta -:--:--\n",
      "                                              0.0/9.5 MB 326.8 kB/s eta 0:00:29\n",
      "                                              0.1/9.5 MB 409.6 kB/s eta 0:00:24\n",
      "                                              0.1/9.5 MB 435.7 kB/s eta 0:00:22\n",
      "                                              0.1/9.5 MB 554.9 kB/s eta 0:00:17\n",
      "                                              0.2/9.5 MB 655.9 kB/s eta 0:00:15\n",
      "     -                                        0.2/9.5 MB 793.0 kB/s eta 0:00:12\n",
      "     -                                        0.3/9.5 MB 655.4 kB/s eta 0:00:15\n",
      "     -                                        0.3/9.5 MB 838.1 kB/s eta 0:00:11\n",
      "     --                                       0.5/9.5 MB 1.0 MB/s eta 0:00:09\n",
      "     --                                       0.7/9.5 MB 1.3 MB/s eta 0:00:07\n",
      "     ---                                      0.9/9.5 MB 1.6 MB/s eta 0:00:06\n",
      "     ----                                     1.1/9.5 MB 1.8 MB/s eta 0:00:05\n",
      "     -----                                    1.3/9.5 MB 2.0 MB/s eta 0:00:05\n",
      "     ------                                   1.5/9.5 MB 2.1 MB/s eta 0:00:04\n",
      "     -------                                  1.7/9.5 MB 2.2 MB/s eta 0:00:04\n",
      "     --------                                 2.0/9.5 MB 2.4 MB/s eta 0:00:04\n",
      "     ---------                                2.2/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "     ----------                               2.4/9.5 MB 2.6 MB/s eta 0:00:03\n",
      "     ----------                               2.5/9.5 MB 2.7 MB/s eta 0:00:03\n",
      "     ----------                               2.6/9.5 MB 2.6 MB/s eta 0:00:03\n",
      "     -----------                              2.6/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "     -----------                              2.8/9.5 MB 2.6 MB/s eta 0:00:03\n",
      "     ------------                             3.0/9.5 MB 2.6 MB/s eta 0:00:03\n",
      "     -------------                            3.2/9.5 MB 2.7 MB/s eta 0:00:03\n",
      "     --------------                           3.4/9.5 MB 2.7 MB/s eta 0:00:03\n",
      "     ---------------                          3.6/9.5 MB 2.8 MB/s eta 0:00:03\n",
      "     ----------------                         3.8/9.5 MB 2.8 MB/s eta 0:00:03\n",
      "     ----------------                         4.0/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     -----------------                        4.1/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     ------------------                       4.3/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     ------------------                       4.4/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     -------------------                      4.7/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     -------------------                      4.7/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     --------------------                     4.9/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     ---------------------                    5.0/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     ---------------------                    5.2/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     ---------------------                    5.2/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     ----------------------                   5.3/9.5 MB 2.8 MB/s eta 0:00:02\n",
      "     -----------------------                  5.7/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     -----------------------                  5.7/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     ------------------------                 5.9/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     -------------------------                6.1/9.5 MB 2.9 MB/s eta 0:00:02\n",
      "     --------------------------               6.4/9.5 MB 3.0 MB/s eta 0:00:02\n",
      "     ----------------------------             6.7/9.5 MB 3.1 MB/s eta 0:00:01\n",
      "     -----------------------------            7.0/9.5 MB 3.1 MB/s eta 0:00:01\n",
      "     ------------------------------           7.2/9.5 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------          7.5/9.5 MB 3.2 MB/s eta 0:00:01\n",
      "     --------------------------------         7.7/9.5 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------        7.9/9.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ----------------------------------       8.2/9.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ----------------------------------       8.3/9.5 MB 3.3 MB/s eta 0:00:01\n",
      "     -----------------------------------      8.4/9.5 MB 3.3 MB/s eta 0:00:01\n",
      "     -----------------------------------      8.5/9.5 MB 3.3 MB/s eta 0:00:01\n",
      "     -----------------------------------      8.6/9.5 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------    8.8/9.5 MB 3.3 MB/s eta 0:00:01\n",
      "     -------------------------------------    8.9/9.5 MB 3.3 MB/s eta 0:00:01\n",
      "     -------------------------------------    9.0/9.5 MB 3.2 MB/s eta 0:00:01\n",
      "     --------------------------------------   9.1/9.5 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.3/9.5 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.5/9.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.5/9.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 9.5/9.5 MB 3.1 MB/s eta 0:00:00\n",
      "Collecting rich>=11.1 (from flax>=0.6.2->tensorflowjs)\n",
      "  Using cached rich-13.4.2-py3-none-any.whl (239 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from flax>=0.6.2->tensorflowjs) (4.6.3)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from flax>=0.6.2->tensorflowjs) (6.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from jax>=0.3.16->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages\\scipy-1.11.0rc2-py3.10-win-amd64.egg (from jax>=0.3.16->tensorflowjs) (1.11.0rc2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages\\pyparsing-2.4.7-py3.10.egg (from packaging~=20.9->tensorflowjs) (2.4.7)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow<3,>=2.12.0->tensorflowjs) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow<3,>=2.12.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow<3,>=2.12.0->tensorflowjs) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow<3,>=2.12.0->tensorflowjs) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow<3,>=2.12.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow<3,>=2.12.0->tensorflowjs) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow<3,>=2.12.0->tensorflowjs) (16.0.0)\n",
      "INFO: pip is looking at multiple versions of tensorflow-intel to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow<3,>=2.1.0 (from tensorflowjs)\n",
      "  Using cached tensorflow-2.12.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "  Using cached tensorflow-2.11.1-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.1 (from tensorflow<3,>=2.1.0->tensorflowjs)\n",
      "  Using cached tensorflow_intel-2.11.1-cp310-cp310-win_amd64.whl (266.3 MB)\n",
      "Requirement already satisfied: setuptools in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (68.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (1.54.2)\n",
      "Collecting tensorboard<2.12,>=2.11 (from tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs)\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs)\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting keras<2.12,>=2.11.0 (from tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs)\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (0.31.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1->flax>=0.6.2->tensorflowjs)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from rich>=11.1->flax>=0.6.2->tensorflowjs) (2.15.1)\n",
      "Collecting chex>=0.1.5 (from optax->flax>=0.6.2->tensorflowjs)\n",
      "  Using cached chex-0.1.7-py3-none-any.whl (89 kB)\n",
      "Collecting jaxlib>=0.1.37 (from optax->flax>=0.6.2->tensorflowjs)\n",
      "  Downloading jaxlib-0.4.13-cp310-cp310-win_amd64.whl (39.1 MB)\n",
      "                                              0.0/39.1 MB ? eta -:--:--\n",
      "                                              0.3/39.1 MB 7.7 MB/s eta 0:00:06\n",
      "                                              0.5/39.1 MB 5.6 MB/s eta 0:00:07\n",
      "                                              0.7/39.1 MB 5.6 MB/s eta 0:00:07\n",
      "                                              0.8/39.1 MB 5.3 MB/s eta 0:00:08\n",
      "                                              0.9/39.1 MB 4.6 MB/s eta 0:00:09\n",
      "                                              0.9/39.1 MB 4.6 MB/s eta 0:00:09\n",
      "     -                                        1.1/39.1 MB 3.4 MB/s eta 0:00:12\n",
      "     -                                        1.3/39.1 MB 3.6 MB/s eta 0:00:11\n",
      "     -                                        1.5/39.1 MB 3.7 MB/s eta 0:00:11\n",
      "     -                                        1.6/39.1 MB 3.5 MB/s eta 0:00:11\n",
      "     -                                        1.7/39.1 MB 3.6 MB/s eta 0:00:11\n",
      "     --                                       2.0/39.1 MB 3.6 MB/s eta 0:00:11\n",
      "     --                                       2.2/39.1 MB 3.8 MB/s eta 0:00:10\n",
      "     --                                       2.5/39.1 MB 3.9 MB/s eta 0:00:10\n",
      "     --                                       2.7/39.1 MB 4.0 MB/s eta 0:00:10\n",
      "     ---                                      3.0/39.1 MB 4.1 MB/s eta 0:00:09\n",
      "     ---                                      3.2/39.1 MB 4.0 MB/s eta 0:00:09\n",
      "     ---                                      3.4/39.1 MB 4.1 MB/s eta 0:00:09\n",
      "     ---                                      3.6/39.1 MB 4.1 MB/s eta 0:00:09\n",
      "     ---                                      3.7/39.1 MB 4.0 MB/s eta 0:00:09\n",
      "     ---                                      3.7/39.1 MB 4.0 MB/s eta 0:00:09\n",
      "     ---                                      3.9/39.1 MB 3.7 MB/s eta 0:00:10\n",
      "     ----                                     4.0/39.1 MB 3.8 MB/s eta 0:00:10\n",
      "     ----                                     4.0/39.1 MB 3.8 MB/s eta 0:00:10\n",
      "     ----                                     4.1/39.1 MB 3.5 MB/s eta 0:00:10\n",
      "     ----                                     4.3/39.1 MB 3.5 MB/s eta 0:00:10\n",
      "     ----                                     4.4/39.1 MB 3.5 MB/s eta 0:00:11\n",
      "     ----                                     4.5/39.1 MB 3.4 MB/s eta 0:00:11\n",
      "     ----                                     4.5/39.1 MB 3.4 MB/s eta 0:00:11\n",
      "     ----                                     4.7/39.1 MB 3.3 MB/s eta 0:00:11\n",
      "     ----                                     4.9/39.1 MB 3.4 MB/s eta 0:00:11\n",
      "     -----                                    5.1/39.1 MB 3.4 MB/s eta 0:00:11\n",
      "     -----                                    5.2/39.1 MB 3.4 MB/s eta 0:00:11\n",
      "     -----                                    5.4/39.1 MB 3.4 MB/s eta 0:00:11\n",
      "     -----                                    5.6/39.1 MB 3.4 MB/s eta 0:00:10\n",
      "     -----                                    5.8/39.1 MB 3.4 MB/s eta 0:00:10\n",
      "     ------                                   6.0/39.1 MB 3.4 MB/s eta 0:00:10\n",
      "     ------                                   6.1/39.1 MB 3.4 MB/s eta 0:00:10\n",
      "     ------                                   6.2/39.1 MB 3.4 MB/s eta 0:00:10\n",
      "     ------                                   6.4/39.1 MB 3.4 MB/s eta 0:00:10\n",
      "     ------                                   6.6/39.1 MB 3.4 MB/s eta 0:00:10\n",
      "     ------                                   6.7/39.1 MB 3.4 MB/s eta 0:00:10\n",
      "     ------                                   6.8/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     ------                                   6.8/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     -------                                  7.0/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     -------                                  7.3/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     -------                                  7.4/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     -------                                  7.4/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     -------                                  7.7/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     --------                                 7.9/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     --------                                 8.0/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     --------                                 8.2/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     --------                                 8.3/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     --------                                 8.5/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     --------                                 8.7/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     ---------                                8.9/39.1 MB 3.3 MB/s eta 0:00:10\n",
      "     ---------                                9.2/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     ---------                                9.2/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     ---------                                9.2/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     ---------                                9.4/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     ---------                                9.6/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     ----------                               9.8/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     ----------                               10.0/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     ----------                               10.2/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     ----------                               10.4/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     ----------                               10.6/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     -----------                              10.8/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     -----------                              10.9/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     -----------                              11.2/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     -----------                              11.3/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     -----------                              11.4/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     -----------                              11.6/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     ------------                             11.8/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     ------------                             11.9/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     ------------                             12.0/39.1 MB 3.4 MB/s eta 0:00:09\n",
      "     ------------                             12.2/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     ------------                             12.3/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     ------------                             12.4/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     ------------                             12.7/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     -------------                            12.9/39.1 MB 3.3 MB/s eta 0:00:09\n",
      "     -------------                            13.1/39.1 MB 3.3 MB/s eta 0:00:08\n",
      "     -------------                            13.3/39.1 MB 3.3 MB/s eta 0:00:08\n",
      "     -------------                            13.5/39.1 MB 3.3 MB/s eta 0:00:08\n",
      "     --------------                           13.8/39.1 MB 3.3 MB/s eta 0:00:08\n",
      "     --------------                           14.0/39.1 MB 3.4 MB/s eta 0:00:08\n",
      "     --------------                           14.2/39.1 MB 3.4 MB/s eta 0:00:08\n",
      "     --------------                           14.3/39.1 MB 3.5 MB/s eta 0:00:08\n",
      "     --------------                           14.6/39.1 MB 3.5 MB/s eta 0:00:08\n",
      "     ---------------                          14.8/39.1 MB 3.6 MB/s eta 0:00:07\n",
      "     ---------------                          14.9/39.1 MB 3.6 MB/s eta 0:00:07\n",
      "     ---------------                          15.1/39.1 MB 3.6 MB/s eta 0:00:07\n",
      "     ---------------                          15.2/39.1 MB 3.5 MB/s eta 0:00:07\n",
      "     ---------------                          15.4/39.1 MB 3.5 MB/s eta 0:00:07\n",
      "     ----------------                         15.7/39.1 MB 3.6 MB/s eta 0:00:07\n",
      "     ----------------                         15.9/39.1 MB 3.6 MB/s eta 0:00:07\n",
      "     ----------------                         16.2/39.1 MB 3.6 MB/s eta 0:00:07\n",
      "     ----------------                         16.5/39.1 MB 3.7 MB/s eta 0:00:07\n",
      "     -----------------                        16.7/39.1 MB 3.7 MB/s eta 0:00:07\n",
      "     -----------------                        17.0/39.1 MB 3.9 MB/s eta 0:00:06\n",
      "     -----------------                        17.2/39.1 MB 3.9 MB/s eta 0:00:06\n",
      "     -----------------                        17.5/39.1 MB 3.9 MB/s eta 0:00:06\n",
      "     ------------------                       17.8/39.1 MB 4.0 MB/s eta 0:00:06\n",
      "     ------------------                       18.1/39.1 MB 4.0 MB/s eta 0:00:06\n",
      "     ------------------                       18.3/39.1 MB 4.1 MB/s eta 0:00:06\n",
      "     ------------------                       18.5/39.1 MB 4.1 MB/s eta 0:00:06\n",
      "     -------------------                      18.8/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     -------------------                      18.9/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     -------------------                      19.0/39.1 MB 4.0 MB/s eta 0:00:05\n",
      "     -------------------                      19.2/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     -------------------                      19.5/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     --------------------                     19.6/39.1 MB 4.2 MB/s eta 0:00:05\n",
      "     --------------------                     19.9/39.1 MB 4.2 MB/s eta 0:00:05\n",
      "     --------------------                     20.1/39.1 MB 4.3 MB/s eta 0:00:05\n",
      "     --------------------                     20.1/39.1 MB 4.3 MB/s eta 0:00:05\n",
      "     --------------------                     20.3/39.1 MB 4.2 MB/s eta 0:00:05\n",
      "     --------------------                     20.5/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     ---------------------                    20.7/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     ---------------------                    20.8/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     ---------------------                    21.0/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     ---------------------                    21.2/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     ---------------------                    21.3/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     ---------------------                    21.5/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     ----------------------                   21.6/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     ----------------------                   21.7/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     ----------------------                   21.8/39.1 MB 4.0 MB/s eta 0:00:05\n",
      "     ----------------------                   22.0/39.1 MB 4.1 MB/s eta 0:00:05\n",
      "     ----------------------                   22.3/39.1 MB 4.2 MB/s eta 0:00:05\n",
      "     -----------------------                  22.5/39.1 MB 4.2 MB/s eta 0:00:04\n",
      "     -----------------------                  22.7/39.1 MB 4.2 MB/s eta 0:00:04\n",
      "     -----------------------                  23.0/39.1 MB 4.3 MB/s eta 0:00:04\n",
      "     -----------------------                  23.2/39.1 MB 4.3 MB/s eta 0:00:04\n",
      "     -----------------------                  23.5/39.1 MB 4.3 MB/s eta 0:00:04\n",
      "     ------------------------                 23.7/39.1 MB 4.3 MB/s eta 0:00:04\n",
      "     ------------------------                 23.8/39.1 MB 4.2 MB/s eta 0:00:04\n",
      "     ------------------------                 24.0/39.1 MB 4.2 MB/s eta 0:00:04\n",
      "     ------------------------                 24.1/39.1 MB 4.2 MB/s eta 0:00:04\n",
      "     ------------------------                 24.3/39.1 MB 4.2 MB/s eta 0:00:04\n",
      "     -------------------------                24.5/39.1 MB 4.1 MB/s eta 0:00:04\n",
      "     -------------------------                24.6/39.1 MB 4.1 MB/s eta 0:00:04\n",
      "     -------------------------                24.7/39.1 MB 4.1 MB/s eta 0:00:04\n",
      "     -------------------------                24.7/39.1 MB 4.0 MB/s eta 0:00:04\n",
      "     -------------------------                24.9/39.1 MB 4.0 MB/s eta 0:00:04\n",
      "     -------------------------                25.1/39.1 MB 4.0 MB/s eta 0:00:04\n",
      "     -------------------------                25.4/39.1 MB 4.1 MB/s eta 0:00:04\n",
      "     --------------------------               25.5/39.1 MB 4.1 MB/s eta 0:00:04\n",
      "     --------------------------               25.6/39.1 MB 4.1 MB/s eta 0:00:04\n",
      "     --------------------------               25.8/39.1 MB 4.1 MB/s eta 0:00:04\n",
      "     --------------------------               26.1/39.1 MB 4.1 MB/s eta 0:00:04\n",
      "     --------------------------               26.4/39.1 MB 4.1 MB/s eta 0:00:04\n",
      "     ---------------------------              26.7/39.1 MB 4.1 MB/s eta 0:00:04\n",
      "     ---------------------------              26.9/39.1 MB 4.1 MB/s eta 0:00:03\n",
      "     ---------------------------              27.2/39.1 MB 4.1 MB/s eta 0:00:03\n",
      "     ----------------------------             27.5/39.1 MB 4.1 MB/s eta 0:00:03\n",
      "     ----------------------------             27.8/39.1 MB 4.1 MB/s eta 0:00:03\n",
      "     ----------------------------             28.0/39.1 MB 4.1 MB/s eta 0:00:03\n",
      "     ----------------------------             28.1/39.1 MB 4.0 MB/s eta 0:00:03\n",
      "     ----------------------------             28.3/39.1 MB 4.0 MB/s eta 0:00:03\n",
      "     ----------------------------             28.3/39.1 MB 4.0 MB/s eta 0:00:03\n",
      "     ----------------------------             28.3/39.1 MB 4.0 MB/s eta 0:00:03\n",
      "     -----------------------------            28.4/39.1 MB 3.8 MB/s eta 0:00:03\n",
      "     -----------------------------            28.7/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     -----------------------------            28.9/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     -----------------------------            29.0/39.1 MB 3.8 MB/s eta 0:00:03\n",
      "     -----------------------------            29.2/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------           29.4/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------           29.6/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------           29.8/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------           30.0/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------           30.1/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------------------------          30.4/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------------------------          30.6/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------------------------          30.9/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------------------------          31.0/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------------------------          31.1/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------------------------          31.1/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------------------------          31.3/39.1 MB 3.9 MB/s eta 0:00:03\n",
      "     --------------------------------         31.4/39.1 MB 3.8 MB/s eta 0:00:03\n",
      "     --------------------------------         31.7/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     --------------------------------         31.9/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     --------------------------------         32.0/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     --------------------------------         32.2/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ---------------------------------        32.4/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ---------------------------------        32.6/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ---------------------------------        32.8/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ---------------------------------        33.1/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ---------------------------------        33.2/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ----------------------------------       33.5/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ----------------------------------       33.7/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ----------------------------------       33.8/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ----------------------------------       33.9/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ----------------------------------       34.1/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     -----------------------------------      34.4/39.1 MB 3.9 MB/s eta 0:00:02\n",
      "     -----------------------------------      34.7/39.1 MB 4.0 MB/s eta 0:00:02\n",
      "     -----------------------------------      34.9/39.1 MB 4.0 MB/s eta 0:00:02\n",
      "     -----------------------------------      35.2/39.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------     35.5/39.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------     35.7/39.1 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------------     36.0/39.1 MB 4.2 MB/s eta 0:00:01\n",
      "     -------------------------------------    36.3/39.1 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------------    36.5/39.1 MB 4.2 MB/s eta 0:00:01\n",
      "     -------------------------------------    36.8/39.1 MB 4.2 MB/s eta 0:00:01\n",
      "     -------------------------------------    37.1/39.1 MB 4.2 MB/s eta 0:00:01\n",
      "     --------------------------------------   37.4/39.1 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------------------   37.7/39.1 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------------------   37.9/39.1 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------------------   38.1/39.1 MB 4.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  38.2/39.1 MB 4.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  38.4/39.1 MB 4.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  38.7/39.1 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  39.0/39.1 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  39.1/39.1 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  39.1/39.1 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  39.1/39.1 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  39.1/39.1 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 39.1/39.1 MB 4.0 MB/s eta 0:00:00\n",
      "Collecting cached_property (from orbax-checkpoint->flax>=0.6.2->tensorflowjs)\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting etils (from orbax-checkpoint->flax>=0.6.2->tensorflowjs)\n",
      "  Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
      "                                              0.0/126.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 126.4/126.4 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nest_asyncio in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from orbax-checkpoint->flax>=0.6.2->tensorflowjs) (1.5.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow<3,>=2.12.0->tensorflowjs) (0.40.0)\n",
      "Collecting dm-tree>=0.1.5 (from chex>=0.1.5->optax->flax>=0.6.2->tensorflowjs)\n",
      "  Downloading dm_tree-0.1.8-cp310-cp310-win_amd64.whl (101 kB)\n",
      "                                              0.0/101.3 kB ? eta -:--:--\n",
      "     -----------------------------------     92.2/101.3 kB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 101.3/101.3 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting toolz>=0.9.0 (from chex>=0.1.5->optax->flax>=0.6.2->tensorflowjs)\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "                                              0.0/55.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 55.8/55.8 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.6.2->tensorflowjs)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (2.20.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs)\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs)\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs)\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "                                              0.0/781.3 kB ? eta -:--:--\n",
      "     -----                                  112.6/781.3 kB 3.3 MB/s eta 0:00:01\n",
      "     -------------                          276.5/781.3 kB 4.3 MB/s eta 0:00:01\n",
      "     ------------------                     389.1/781.3 kB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------              532.5/781.3 kB 3.0 MB/s eta 0:00:01\n",
      "     ---------------------------------      686.1/781.3 kB 3.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 781.3/781.3 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow<3,>=2.1.0->tensorflowjs) (3.2.2)\n",
      "Installing collected packages: tensorboard-plugin-wit, msgpack, dm-tree, cached_property, toolz, tensorstore, tensorflow-estimator, tensorboard-data-server, protobuf, packaging, mdurl, keras, importlib_resources, etils, tensorflow-hub, markdown-it-py, jaxlib, rich, orbax-checkpoint, google-auth-oauthlib, chex, tensorboard, optax, tensorflow-intel, flax, tensorflow, tensorflowjs\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.12.0\n",
      "    Uninstalling tensorflow-estimator-2.12.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.1\n",
      "    Uninstalling tensorboard-data-server-0.7.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 1.0.0\n",
      "    Uninstalling google-auth-oauthlib-1.0.0:\n",
      "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.3\n",
      "    Uninstalling tensorboard-2.12.3:\n",
      "      Successfully uninstalled tensorboard-2.12.3\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.12.0\n",
      "    Uninstalling tensorflow-intel-2.12.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.12.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.12.0\n",
      "    Uninstalling tensorflow-2.12.0:\n",
      "      Successfully uninstalled tensorflow-2.12.0\n",
      "Successfully installed cached_property-1.5.2 chex-0.1.7 dm-tree-0.1.8 etils-1.3.0 flax-0.6.11 google-auth-oauthlib-0.4.6 importlib_resources-5.12.0 jaxlib-0.4.13 keras-2.11.0 markdown-it-py-3.0.0 mdurl-0.1.2 msgpack-1.0.5 optax-0.1.5 orbax-checkpoint-0.2.6 packaging-20.9 protobuf-3.19.6 rich-13.4.2 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.1 tensorflow-estimator-2.11.0 tensorflow-hub-0.12.0 tensorflow-intel-2.11.1 tensorflowjs-3.21.0 tensorstore-0.1.39 toolz-0.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "object-detection 0.1 requires apache-beam, which is not installed.\n",
      "object-detection 0.1 requires avro-python3, which is not installed.\n",
      "object-detection 0.1 requires contextlib2, which is not installed.\n",
      "tf-models-official 2.12.0 requires google-api-python-client>=1.6.7, which is not installed.\n",
      "tf-models-official 2.12.0 requires immutabledict, which is not installed.\n",
      "tf-models-official 2.12.0 requires kaggle>=1.3.9, which is not installed.\n",
      "tf-models-official 2.12.0 requires oauth2client, which is not installed.\n",
      "tf-models-official 2.12.0 requires opencv-python-headless, which is not installed.\n",
      "tf-models-official 2.12.0 requires py-cpuinfo>=3.3.0, which is not installed.\n",
      "tf-models-official 2.12.0 requires sentencepiece, which is not installed.\n",
      "tf-models-official 2.12.0 requires seqeval, which is not installed.\n",
      "tf-models-official 2.12.0 requires tensorflow-datasets, which is not installed.\n",
      "tf-models-official 2.12.0 requires tensorflow-model-optimization>=0.4.1, which is not installed.\n",
      "tf-models-official 2.12.0 requires tensorflow-text~=2.12.0, which is not installed.\n",
      "tf-models-official 2.12.0 requires pyyaml<6.0,>=5.1, but you have pyyaml 6.0 which is incompatible.\n",
      "tf-models-official 2.12.0 requires tensorflow~=2.12.0, but you have tensorflow 2.11.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0oxbVynHpfDK"
   },
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB2AGNmJpfDK",
    "outputId": "fbc9f747-f511-47e8-df8f-5ea65cef0374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default Tensorflow\\workspace\\models\\my_ssd_mobnet\\export\\saved_model Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfjsexport\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7rfT4-hpfDK",
    "outputId": "532707fd-6feb-4bc6-84a3-325b5d16303c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weight file Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfjsexport\\model.json...\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8_hm-itpfDK"
   },
   "outputs": [],
   "source": [
    "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jax in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (0.4.12)\n",
      "Collecting jax\n",
      "  Downloading jax-0.4.13.tar.gz (1.3 MB)\n",
      "                                              0.0/1.3 MB ? eta -:--:--\n",
      "                                              0.0/1.3 MB 1.4 MB/s eta 0:00:01\n",
      "                                              0.0/1.3 MB 1.4 MB/s eta 0:00:01\n",
      "                                              0.0/1.3 MB 1.4 MB/s eta 0:00:01\n",
      "                                              0.0/1.3 MB 1.4 MB/s eta 0:00:01\n",
      "     --                                       0.1/1.3 MB 375.8 kB/s eta 0:00:04\n",
      "     --                                       0.1/1.3 MB 375.8 kB/s eta 0:00:04\n",
      "     ---                                      0.1/1.3 MB 328.2 kB/s eta 0:00:04\n",
      "     -----                                    0.2/1.3 MB 436.9 kB/s eta 0:00:03\n",
      "     ------                                   0.2/1.3 MB 479.2 kB/s eta 0:00:03\n",
      "     --------                                 0.3/1.3 MB 568.9 kB/s eta 0:00:02\n",
      "     --------                                 0.3/1.3 MB 571.2 kB/s eta 0:00:02\n",
      "     --------                                 0.3/1.3 MB 571.2 kB/s eta 0:00:02\n",
      "     --------                                 0.3/1.3 MB 571.2 kB/s eta 0:00:02\n",
      "     --------                                 0.3/1.3 MB 571.2 kB/s eta 0:00:02\n",
      "     --------                                 0.3/1.3 MB 571.2 kB/s eta 0:00:02\n",
      "     ------------                             0.4/1.3 MB 544.1 kB/s eta 0:00:02\n",
      "     -------------                            0.4/1.3 MB 526.8 kB/s eta 0:00:02\n",
      "     -------------                            0.5/1.3 MB 531.8 kB/s eta 0:00:02\n",
      "     --------------                           0.5/1.3 MB 538.3 kB/s eta 0:00:02\n",
      "     ---------------                          0.5/1.3 MB 535.5 kB/s eta 0:00:02\n",
      "     ----------------                         0.5/1.3 MB 541.1 kB/s eta 0:00:02\n",
      "     -----------------                        0.6/1.3 MB 528.1 kB/s eta 0:00:02\n",
      "     ------------------                       0.6/1.3 MB 560.4 kB/s eta 0:00:02\n",
      "     -------------------                      0.7/1.3 MB 581.7 kB/s eta 0:00:02\n",
      "     ---------------------                    0.7/1.3 MB 578.0 kB/s eta 0:00:02\n",
      "     ----------------------                   0.7/1.3 MB 589.2 kB/s eta 0:00:01\n",
      "     -----------------------                  0.8/1.3 MB 583.5 kB/s eta 0:00:01\n",
      "     -----------------------                  0.8/1.3 MB 592.1 kB/s eta 0:00:01\n",
      "     -----------------------                  0.8/1.3 MB 592.1 kB/s eta 0:00:01\n",
      "     ------------------------                 0.8/1.3 MB 568.9 kB/s eta 0:00:01\n",
      "     ---------------------------              0.9/1.3 MB 599.9 kB/s eta 0:00:01\n",
      "     ----------------------------             0.9/1.3 MB 607.6 kB/s eta 0:00:01\n",
      "     ------------------------------           1.0/1.3 MB 629.3 kB/s eta 0:00:01\n",
      "     ------------------------------           1.0/1.3 MB 623.7 kB/s eta 0:00:01\n",
      "     --------------------------------         1.1/1.3 MB 649.4 kB/s eta 0:00:01\n",
      "     -----------------------------------      1.2/1.3 MB 679.5 kB/s eta 0:00:01\n",
      "     -------------------------------------    1.2/1.3 MB 696.2 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.3/1.3 MB 718.6 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from jax) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.21 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from jax) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages (from jax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in e:\\project\\tensorflow object detection\\tfodcourse\\tfod\\lib\\site-packages\\scipy-1.11.0rc2-py3.10-win-amd64.egg (from jax) (1.11.0rc2)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.13-py3-none-any.whl size=1518835 sha256=a67fab395105a8e89295bd563c2c49f0dc21193d0c0a1fc18170b65098425461\n",
      "  Stored in directory: c:\\users\\avita\\appdata\\local\\pip\\cache\\wheels\\f3\\7a\\25\\f297f69029b5e4064e4736a0c4b3996a44cc27781c120bcb99\n",
      "Successfully built jax\n",
      "Installing collected packages: jax\n",
      "  Attempting uninstall: jax\n",
      "    Found existing installation: jax 0.4.12\n",
      "    Uninstalling jax-0.4.12:\n",
      "      Successfully uninstalled jax-0.4.12\n",
      "Successfully installed jax-0.4.13\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtUw73FHpfDK"
   },
   "source": [
    "# 12. Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XviMtewLpfDK"
   },
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "us86cjC4pfDL"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1r5YO3rpfDL",
    "outputId": "5fcdf7a4-eee2-4365-f1ca-1751968379ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow\\models\\research\\object_detection\\export_tflite_graph_tf2.py  --pipeline_config_path=Tensorflow\\workspace\\models\\my_ssd_mobnet\\pipeline.config --trained_checkpoint_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet --output_directory=Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfliteexport\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-xWpHN8pfDL",
    "outputId": "7f6bacd8-d077-43b5-c131-5b081fba24a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Project\\Tensorflow Object Detection\\TFODCourse\\tfod\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "I0626 11:29:30.439337 13884 api.py:459] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "WARNING:tensorflow:From E:\\Project\\Tensorflow Object Detection\\TFODCourse\\tfod\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0626 11:29:35.257764 13884 deprecation.py:350] From E:\\Project\\Tensorflow Object Detection\\TFODCourse\\tfod\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "I0626 11:29:39.063527 13884 api.py:459] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "I0626 11:29:44.088019 13884 api.py:459] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x00000279E29D3DC0>, because it is not built.\n",
      "W0626 11:29:46.520563 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x00000279E29D3DC0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000279E4757790>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000279E4757790>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2D4FEE0>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2D4FEE0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EB61D0>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EB61D0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000279E2EB6D40>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000279E2EB6D40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E4795E40>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E4795E40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EFD240>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EFD240>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000279E2EFE920>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000279E2EFE920>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2EFF580>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2EFF580>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EFEAD0>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EFEAD0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000279E2EFF4C0>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000279E2EFF4C0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2EFD630>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2EFD630>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EFEF20>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EFEF20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E3009F30>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E3009F30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E301E920>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E301E920>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E301DF00>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E301DF00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E423D0C0>, because it is not built.\n",
      "W0626 11:29:47.104696 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E423D0C0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E423E260>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E423E260>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E423EB00>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E423EB00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E423F1F0>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E423F1F0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E423DA50>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E423DA50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E423E440>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E423E440>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E428E380>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E428E380>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E428FA90>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E428FA90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E428F220>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E428F220>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E428E0E0>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E428E0E0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E428D000>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E428D000>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E428D690>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E428D690>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E428E0B0>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E428E0B0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E428EDD0>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E428EDD0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2E953C0>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2E953C0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2E955A0>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2E955A0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2E95780>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2E95780>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2E944F0>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2E944F0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2E97790>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2E97790>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2E96500>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2E96500>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E419BA60>, because it is not built.\n",
      "W0626 11:29:47.108694 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E419BA60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E4199900>, because it is not built.\n",
      "W0626 11:29:47.112695 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E4199900>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E422E8C0>, because it is not built.\n",
      "W0626 11:29:47.112695 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E422E8C0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2EEF820>, because it is not built.\n",
      "W0626 11:29:47.112695 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2EEF820>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EEC400>, because it is not built.\n",
      "W0626 11:29:47.112695 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EEC400>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2EEC6D0>, because it is not built.\n",
      "W0626 11:29:47.112695 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2EEC6D0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EED360>, because it is not built.\n",
      "W0626 11:29:47.112695 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EED360>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2EEC3A0>, because it is not built.\n",
      "W0626 11:29:47.112695 13884 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000279E2EEC3A0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EEEB60>, because it is not built.\n",
      "W0626 11:29:47.112695 13884 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x00000279E2EEEB60>, because it is not built.\n",
      "W0626 11:30:19.212738 13884 save.py:271] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfliteexport\\saved_model\\assets\n",
      "I0626 11:30:29.217746 13884 builder_impl.py:797] Assets written to: Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfliteexport\\saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iJfYMbN6pfDL"
   },
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8GwUeoFpfDL",
    "outputId": "fac43ea4-cc85-471b-a362-e994b06fd583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tflite_convert --saved_model_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfliteexport\\saved_model --output_file=Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfliteexport\\saved_model\\detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --allow_custom_ops\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbd7gqHMpfDL",
    "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 11:31:43.630434: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-06-26 11:31:43.631300: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NQqZRdA21Uc"
   },
   "source": [
    "# 13. Zip and Export Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTVTGCQp2ZJJ"
   },
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whShhB0x3PYJ",
    "outputId": "b773201d-35c9-46a8-b893-4a76bd4d5d97"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
